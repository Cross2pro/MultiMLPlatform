version: '3.8'

services:
  # 后端Flask服务
  backend:
    build:
      context: ./ml-prediction-system-backend-flask
      dockerfile: Dockerfile
    container_name: ml-backend-prod
    environment:
      - FLASK_ENV=production
      - FLASK_DEBUG=False
    volumes:
      - logs_data:/app/logs
    networks:
      - ml-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # 前端Next.js服务
  frontend:
    build:
      context: ./ml-prediction-system
      dockerfile: Dockerfile
    container_name: ml-frontend-prod
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=/api
    depends_on:
      - backend
    networks:
      - ml-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

  # Nginx反向代理
  nginx:
    image: nginx:alpine
    container_name: ml-nginx-prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - logs_data:/var/log/nginx
    depends_on:
      - frontend
      - backend
    networks:
      - ml-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

networks:
  ml-network:
    driver: bridge

volumes:
  logs_data:
    driver: local 